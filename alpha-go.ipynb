{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Algorithme Alpha Go\n",
    "\n",
    "AlphaGo 14h axées Dev:\n",
    "- on code\n",
    "- tournoi de go\n",
    "- projets en binômes\n",
    "- prendre la parole\n",
    "\n",
    "## ML sur le GOBAN\n",
    "9*9 ou 13*13\n",
    "voir comment la difficulté d'apprentissage augmente avec la taille du goban\n",
    "\n",
    "<br>\n",
    "\n",
    "Goban =\n",
    "- legal_moves() -> [liste de moves]\n",
    "- push(m) -> exécute le move m\n",
    "- pop() -> défait le dernier coup\n",
    "\n",
    "<br>\n",
    "\n",
    "AlphaGo = 2 RNN\n",
    "- un pour les priors -> probas de gain suivant chaque move pour un board \n",
    "-> !! attention aux moves interdits !!\n",
    "- un pour le rollout -> donner un move 'réaliste' \n",
    "\n",
    "<br>\n",
    "\n",
    "rollout = (ensemble de moves aléatoires) -> victoire/défaite\n",
    "- on évalue le premier move (a1) qui a été choisi en fonction du résultat du rollout\n",
    "- on renforce l'arbre de a1 par le même procédé appliqué à a2\n",
    "\n",
    "input RL = plateau\n",
    "\n",
    "<br>\n",
    "\n",
    "Puis mettre en oeuvre de l'apprentissage par renforcement\n",
    "\n",
    "Comment on rate un board ?\n",
    "\n",
    "Workflow :\n",
    "Choisir un move selon un plateau\n",
    "- proba pour chaque move\n",
    "- proba donnée par PRIOR\n",
    "- PRIOR entraîné par rollout"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}